{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aE1I7pE93qRg"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    TFDistilBertForSequenceClassification,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F53xT40g304y",
    "outputId": "827bbec6-6eea-48c7-9de3-b88229c8806f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stopw = stopwords.words(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eK0I7fb-4Csr"
   },
   "outputs": [],
   "source": [
    "root_path = \"bbc-text.csv\"\n",
    "df = pd.read_csv(root_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "avC0MFF24Ia_"
   },
   "outputs": [],
   "source": [
    "df[\"encoded_text\"] = df[\"category\"].astype(\"category\").cat.codes\n",
    "num_labels = df[\"encoded_text\"].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EXQXLl4z4PMI"
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"text\"].tolist(), df[\"encoded_text\"].tolist(),\n",
    "    test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "41bb15574438461fb2c070a3615854f3",
      "9f305a51b3034d21b7b467050c2de535",
      "6c4ede3d3a5441a086099feb9718b848",
      "9e4eab0e56d44e85b28d7ac50630926a",
      "5e397de5e00f4add9990e9913faa1ed1",
      "ac6547382348489db7bfa73e1759803f",
      "0de8d6e2964a45608b28408cffa9ed34",
      "c4f0431e6d0543988708ee541d37efdf",
      "cddf4832227b40c3b29c801839f719af",
      "759e6f53cdb446518a8b93faa13931bd",
      "69176e28b0aa46b888d6b94cf7648a16",
      "cea46fa219084f78832d9e87b9875796",
      "dbd53158533147b2be5d06fe0d19d8bd",
      "7b05c3acfc7f43baa4c403cfd6427cf9",
      "d1e74c49220345f18aa072b5b3965e8b",
      "71b72dc9becc4b528c8ae83ddccbd5ed",
      "b468cee24ab3422cbd47d01040048020",
      "be3944599b9f4d098649ab10fbf68461",
      "3d4b8670d5fe42749baeb75936af58a9",
      "2141879c2780457caad13973c9d0e199",
      "27d0d280482146788c724b0683d7a5df",
      "800cde22c5d24b93be9896ac4bc0695b",
      "88a36d8e63d34fe28605e7a0e7c6f713",
      "20ef297dd22342cca509b0131ac7f9af",
      "083dcbbed03c47a18f830eadcbad5d9a",
      "5343bd256f1c401586eabc60e7c898a8",
      "862fe2f9a78a463f9de0a56ba95b4211",
      "5dd5812d588748bea29a0a7a4127fb65",
      "71628bf50c2a4f9899e2f98ff8ebb7cd",
      "413c96dbb2e2442ab94102cceb14fa11",
      "0b71df8425ce434e8f37462898236fa1",
      "018238af69db430cad84bf72be4da1b6",
      "c0219d2e09014e38840aa269532566e8",
      "3ce015c7ea2d41899ab2ce37e8978d51",
      "10f28a9f7fc345b5abcca2910b9db5de",
      "2eeed4298a094a2c95c658d8ab8b1ed3",
      "e0b12665448f4d8c93b7fc0711b09a3b",
      "be3fe5f7ef11407dbed89606788d9d72",
      "2361bfe26fd84990be652c1d9d115a5e",
      "b76bd9ed157e49cfa26759eda3af3f59",
      "c57bbf61b6324860a60927d35271b148",
      "4a92b02d47004cf292cd92bcd6930750",
      "278fd8d7a7324345a06fcf924ee71cef",
      "038f76144ef5415c8374c6a0d0d00747"
     ]
    },
    "id": "Ln3cfHJT4VV-",
    "outputId": "92925e3e-768a-4090-8828-5b96f6088a88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bb15574438461fb2c070a3615854f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea46fa219084f78832d9e87b9875796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a36d8e63d34fe28605e7a0e7c6f713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce015c7ea2d41899ab2ce37e8978d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QXZt8DUX4Z5I"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "i-BIpDli4dAf"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    tf.convert_to_tensor(train_labels)\n",
    ")).shuffle(1000).batch(16)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    tf.convert_to_tensor(val_labels)\n",
    ")).batch(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyeitQOE4jYk",
    "outputId": "6b2baddf-ddc4-48ff-f1e4-f1215d8b77e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'dropout_39', 'pre_classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels,\n",
    "    use_safetensors=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Lskb1ur5YYm",
    "outputId": "d40b3ee9-0ec3-40d8-ea13-1ad6c842f13c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "69/69 [==============================] - 124s 1s/step - loss: 0.5504 - accuracy: 0.8886 - val_loss: 0.1143 - val_accuracy: 0.9672\n",
      "Epoch 2/3\n",
      "69/69 [==============================] - 67s 971ms/step - loss: 0.0893 - accuracy: 0.9808 - val_loss: 0.1035 - val_accuracy: 0.9708\n",
      "Epoch 3/3\n",
      "69/69 [==============================] - 66s 958ms/step - loss: 0.0336 - accuracy: 0.9963 - val_loss: 0.0688 - val_accuracy: 0.9745\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5, epsilon=1e-08)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEu5iBb66Pot",
    "outputId": "4e3d5035-d23e-4bc5-c2e4-0e685d743d7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_models/tokenizer_config.json',\n",
       " './saved_models/special_tokens_map.json',\n",
       " './saved_models/vocab.txt',\n",
       " './saved_models/added_tokens.json',\n",
       " './saved_models/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_directory = \"./saved_models\"\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwbDC9pE7WKH",
    "outputId": "1c8cb502-2a26-4506-f35f-154728c0fd6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ./saved_models were not used when initializing TFDistilBertForSequenceClassification: ['dropout_39']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at ./saved_models and are newly initialized: ['dropout_59']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_fine_tuned = DistilBertTokenizerFast.from_pretrained(save_directory)\n",
    "model_fine_tuned = TFDistilBertForSequenceClassification.from_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GlRkD2GO7feA",
    "outputId": "c78b9a99-2298-4a17-ea62-130080ca3115"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n"
     ]
    }
   ],
   "source": [
    "test_text = val_texts[0]\n",
    "inputs = tokenizer_fine_tuned(test_text, return_tensors=\"tf\", truncation=True, padding=True)\n",
    "outputs = model_fine_tuned(inputs)\n",
    "prediction_value = tf.argmax(outputs.logits, axis=1).numpy()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wmYdBzY7mYj",
    "outputId": "10ac142b-745c-4b45-a766-f5b72f5ea1e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted label:\", prediction_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1tB024WN7tES",
    "outputId": "d3b24a5f-d2f6-4cc3-de45-d8c033a45f45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_4', 'score': 0.9878628253936768}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model=model_fine_tuned, tokenizer=tokenizer_fine_tuned)\n",
    "print(classifier(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmyW7CrD7ycl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
